# Проект 0. Угадай число

## Оглавление  
[1. Описание проекта](https://github.com/Niclausiv/sf_data_science/blob/main/project_1/README.md#Описание-проекта)  
[2. Какой кейс решаем?](https://github.com/Niclausiv/sf_data_science/blob/main/project_1/README.md#Какой-кейс-решаем?)  
[3. Краткая информация о данных](https://github.com/Niclausiv/sf_data_science/blob/main/project_1/README.md#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](https://github.com/Niclausiv/sf_data_science/blob/main/project_1/README.md#Этапы-работы-над-проектом)  
[5. Результат](https://github.com/Niclausiv/sf_data_science/blob/main/project_1/README.md#Результат)    
[6. Выводы](https://github.com/Niclausiv/sf_data_science/blob/main/project_1/README.md#Выводы) 

### Описание проекта    
Имеется  база резюме, выгруженная с сайта поиска вакансий hh.ru.
Проблематика: часть соискателей не указывает желаемую заработную плату, когда составляет своё резюме.
Это является помехой для рекомендательной системы HeadHunter, которая подбирает соискателям список наиболее подходящих вакансий, а работодателям — список наиболее подходящих специалистов.



:arrow_up:[к оглавлению](https://github.com/Niclausiv/sf_data_science/blob/main/project_1/README.md#Оглавление)

### Какой кейс решаем?    
 Необходимо  преобразовать, исследовать и очистить данные, чтобы в дальнейшем можно было построить модель, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе.

**Условия соревнования:**  
- Внимательно изучить детали задачи.
- Скачать уже знакомый датасет и ноутбук-шаблон
- Обязательно ознакомиться с дополнительным теоретическим материалом, который даётся перед заданием.
- Ответить на все контрольные вопросы
- Загрузить ноутбук со своим решением на GitHub, оформив его в соответствии с требованиями.


**Метрика качества**     
- Решение оформляется только в Jupyter Notebook.
- Решение оформляется в соответствии с ноутбуком-шаблоном.
- Каждое задание выполняется в отдельной ячейке, выделенной под задание.
- Решение должно использовать только пройденный материал
- Код должен быть читаемым и понятным
- Обязательное требование: графики должны содержать название, отражающее их суть, и подписи осей
- Выводы к графикам оформляются в формате Markdown

**Что практикуем**     
Учимся писать код согласно PEP8, преобразовать, исследовать и очищать данные.

### Краткая информация о данных
База резюме, выгруженная с сайта поиска вакансий hh.ru в виде csv файла, размером 456 Мб.
В ней содержится информация о 44744 вакансиях в виде 12 признаков типа object.
Исходный [датасет](https://drive.google.com/file/d/1Kb78mAWYKcYlellTGhIjPI-bCcKbGuTn/view?usp=sharing)
  
:arrow_up:[к оглавлению](https://github.com/Niclausiv/sf_data_science/tree/main/project_1/README.md#Оглавление)

### Этапы работы над проектом  
1. Базовый анализ структуры данных
2. Преобразование данных
3. Разведывательный анализ
4. Очистка данных

:arrow_up:[к оглавлению](https://github.com/Niclausiv/sf_data_science/tree/main/project_1/README.md#Оглавление)

### Результат  
Получен очищенный от выбросов и пропусков датасет. 
Задача успешно решена. 

:arrow_up:[к оглавлению](https://github.com/Niclausiv/sf_data_science/tree/main/project_1/README.md#Оглавление)

### Выводы  
В процессе работы над датасетом был проведен анализ, созданы новые признаки, построены графики зависимостей, была осуществленна очистка данных от пропусков, выбросов. 

:arrow_up:[к оглавлению](https://github.com/Niclausiv/sf_data_science/tree/main/project_1/README.md#Оглавление)

Если информация по этому проекту покажется вам интересной или полезной, то я буду очень вам благодарен, если отметите репозиторий и профиль ⭐️⭐️⭐️-дами